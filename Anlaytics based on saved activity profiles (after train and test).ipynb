{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b01a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def all_activity(\n",
    "    spikes: torch.Tensor, assignments: torch.Tensor, n_labels: int\n",
    ") -> torch.Tensor:\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Classify data with the label with highest average spiking activity over all neurons.\n",
    "\n",
    "    :param spikes: Binary tensor of shape ``(n_samples, time, n_neurons)`` of a layer's\n",
    "        spiking activity.\n",
    "    :param assignments: A vector of shape ``(n_neurons,)`` of neuron label assignments.\n",
    "    :param n_labels: The number of target labels in the data.\n",
    "    :return: Predictions tensor of shape ``(n_samples,)`` resulting from the \"all\n",
    "        activity\" classification scheme.\n",
    "    \"\"\"\n",
    "    n_samples = spikes.size(0)\n",
    "\n",
    "    rates = torch.zeros((n_samples, n_labels), device=spikes.device)\n",
    "    for i in range(n_labels):\n",
    "        # Count the number of neurons with this label assignment.\n",
    "        n_assigns = torch.sum(assignments == i).float()\n",
    "\n",
    "        if n_assigns > 0:\n",
    "            # Get indices of samples with this label.\n",
    "            indices = torch.nonzero(assignments == i).view(-1)\n",
    "\n",
    "            # Compute layer-wise firing rate for this label.\n",
    "            rates[:, i] = torch.sum(spikes[:, indices], 1) / n_assigns\n",
    "\n",
    "    # Predictions are arg-max of layer-wise firing rates.\n",
    "    return torch.sort(rates, dim=1, descending=True)[1][:, 0]\n",
    "\n",
    "\n",
    "def proportion_weighting(\n",
    "    spikes: torch.Tensor,\n",
    "    assignments: torch.Tensor,\n",
    "    proportions: torch.Tensor,\n",
    "    n_labels: int,\n",
    ") -> torch.Tensor:\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Classify data with the label with highest average spiking activity over all neurons,\n",
    "    weighted by class-wise proportion.\n",
    "\n",
    "    :param spikes: Binary tensor of shape ``(n_samples, time, n_neurons)`` of a single\n",
    "        layer's spiking activity.\n",
    "    :param assignments: A vector of shape ``(n_neurons,)`` of neuron label assignments.\n",
    "    :param proportions: A matrix of shape ``(n_neurons, n_labels)`` giving the per-class\n",
    "        proportions of neuron spiking activity.\n",
    "    :param n_labels: The number of target labels in the data.\n",
    "    :return: Predictions tensor of shape ``(n_samples,)`` resulting from the \"proportion\n",
    "        weighting\" classification scheme.\n",
    "    \"\"\"\n",
    "    n_samples = spikes.size(0)\n",
    "\n",
    "    rates = torch.zeros((n_samples, n_labels), device=spikes.device)\n",
    "    for i in range(n_labels):\n",
    "        # Count the number of neurons with this label assignment.\n",
    "        n_assigns = torch.sum(assignments == i).float()\n",
    "\n",
    "        if n_assigns > 0:\n",
    "            # Get indices of samples with this label.\n",
    "            indices = torch.nonzero(assignments == i).view(-1)\n",
    "\n",
    "            # Compute layer-wise firing rate for this label.\n",
    "            rates[:, i] += (\n",
    "                torch.sum((proportions[:, i] * spikes)[:, indices], 1) / n_assigns\n",
    "            )\n",
    "\n",
    "    # Predictions are arg-max of layer-wise firing rates.\n",
    "    predictions = torch.sort(rates, dim=1, descending=True)[1][:, 0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def pop_prediction(\n",
    "    spikes: torch.Tensor, label_profiles: torch.Tensor, n_labels: int\n",
    ") -> torch.Tensor:\n",
    "    # language=rst\n",
    "    \"\"\"\n",
    "    Classify data with the label with highest aligned output activity profile.\n",
    "\n",
    "    :param spikes: Binary tensor of shape ``(n_samples, time, n_neurons)`` of a layer's\n",
    "        spiking activity.\n",
    "    :param label_profiles: A vector of shape ``(n_neurons, n_labels)`` of neuron label assignments.\n",
    "    :param n_labels: The number of target labels in the data.\n",
    "    :return: Predictions tensor of shape ``(n_samples,)`` resulting from the \"all\n",
    "        activity\" classification scheme.\n",
    "    \"\"\"\n",
    "\n",
    "    #calculate align of each profile to the label profiles\n",
    "    fits = torch.mm(spikes, label_profiles)\n",
    "\n",
    "    # Predictions are arg-max of population activity vector products with label_profiles.\n",
    "    return torch.sort(fits, dim=1, descending=True)[1][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ad4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recurrent nets\n",
    "\n",
    "endpoint_delays = [\"50\", \"100\", \"200\"]\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "clf = []\n",
    "label_profiles = []\n",
    "assignments = []\n",
    "proportions = []\n",
    "\n",
    "#load everything\n",
    "for i in range(1):\n",
    "    data.append(torch.load(f'sdg_classification/norm_activities.pt').cpu().detach().numpy())\n",
    "    labels.append(torch.load(f'sdg_classification/labelling.pt').cpu().detach().numpy())\n",
    "    labels[i] = labels[i].reshape((2230))\n",
    "    \n",
    "    test_data.append(torch.load(f'sdg_classification/test_norm_activities.pt').cpu().detach().numpy())\n",
    "    test_labels.append(torch.load(f'sdg_classification/test_labelling.pt').cpu().detach().numpy())\n",
    "    \n",
    "    clf.append(make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3, loss='modified_huber')))\n",
    "    clf[i].fit(data[i], labels[i])\n",
    "    \n",
    "    label_profiles.append(torch.load(f'label_profiles/final_profiles.pt').cpu().detach().numpy())\n",
    "    \n",
    "    assignments.append(torch.load(f'neuron_eval/final_assignments_at_100%.pt').cpu().detach().numpy())\n",
    "    proportions.append(torch.load(f'neuron_eval/final_proportions_at_100%.pt').cpu().detach().numpy())\n",
    "    \n",
    "#predict stuff train\n",
    "train_correct = []\n",
    "train_pred_svm = []\n",
    "train_pred_pop = []\n",
    "train_pred_all = []\n",
    "train_pred_prop = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    train_correct.append([0,0,0,0])\n",
    "    train_pred_svm.append(clf[i].predict(data[i]))\n",
    "    data_tensor = torch.from_numpy(data[i])\n",
    "    label_profiles_tensor = torch.from_numpy(label_profiles[i])\n",
    "    assignments_tensor = torch.from_numpy(assignments[i])\n",
    "    proportions_tensor = torch.from_numpy(proportions[i])\n",
    "\n",
    "    train_pred_pop.append(pop_prediction(data_tensor, label_profiles_tensor, 10))\n",
    "    train_pred_all.append(all_activity(data_tensor, assignments_tensor, 10))\n",
    "    train_pred_prop.append(proportion_weighting(data_tensor, assignments_tensor, proportions_tensor, 10))\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for label in labels[i]:    \n",
    "        if(train_pred_svm[i][counter] == label): train_correct[i][0] += 1\n",
    "        if(train_pred_pop[i][counter] == label): train_correct[i][1] += 1\n",
    "        if(train_pred_all[i][counter] == label): train_correct[i][2] += 1\n",
    "        if(train_pred_prop[i][counter] == label): train_correct[i][3] += 1\n",
    "        \n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "n_train = counter + 1\n",
    "        \n",
    "#predict stuff test\n",
    "test_correct = []\n",
    "test_pred_svm = []\n",
    "test_pred_pop = []\n",
    "test_pred_all = []\n",
    "test_pred_prop= []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    test_correct.append([0,0,0,0])\n",
    "    test_pred_svm.append(clf[i].predict(test_data[i]))\n",
    "    test_data_tensor = torch.from_numpy(test_data[i])\n",
    "    label_profiles_tensor = torch.from_numpy(label_profiles[i])\n",
    "    assignments_tensor = torch.from_numpy(assignments[i])\n",
    "    proportions_tensor = torch.from_numpy(proportions[i])\n",
    "    \n",
    "    test_pred_pop.append(pop_prediction(test_data_tensor, label_profiles_tensor, 10))\n",
    "    test_pred_all.append(all_activity(test_data_tensor, assignments_tensor, 10))\n",
    "    test_pred_prop.append(proportion_weighting(test_data_tensor, assignments_tensor, proportions_tensor, 10))\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for label in test_labels[i]:\n",
    "        if(test_pred_svm[i][counter] == label): test_correct[i][0] += 1\n",
    "        if(test_pred_pop[i][counter] == label): test_correct[i][1] += 1\n",
    "        if(test_pred_all[i][counter] == label): test_correct[i][2] += 1\n",
    "        if(test_pred_prop[i][counter] == label): test_correct[i][3] += 1\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "n_test = counter + 1\n",
    "\n",
    "#convert to accuracies\n",
    "svm_acc = [[],[]]\n",
    "pop_acc = [[],[]]\n",
    "all_acc = [[],[]]\n",
    "prop_acc = [[],[]]\n",
    "\n",
    "for i in range(1):\n",
    "    svm_acc[0].append(train_correct[i][0]/n_train)\n",
    "    svm_acc[1].append(test_correct[i][0]/n_test)\n",
    "    pop_acc[0].append(train_correct[i][1]/n_train)\n",
    "    pop_acc[1].append(test_correct[i][1]/n_test)\n",
    "    all_acc[0].append(train_correct[i][2]/n_train)\n",
    "    all_acc[1].append(test_correct[i][2]/n_test)\n",
    "    prop_acc[0].append(train_correct[i][3]/n_train)\n",
    "    prop_acc[1].append(test_correct[i][3]/n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffbf36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.575974899148364], [0.32684652808491815]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ca76ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4069923800986105], [0.33171163202122955]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5a895c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.42088749439713136], [0.2998673153471915]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d8f2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4625728372926939], [0.32596196373286157]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4edc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f22bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f57eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f56765bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime constant (in ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, fontweight \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbarWidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_delays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#plt.title(\"(a)\", fontsize=30)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.9/site-packages/matplotlib/pyplot.py:1795\u001b[0m, in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m         l\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1795\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_xticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m locs, labels\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.9/site-packages/matplotlib/axes/_base.py:75\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.9/site-packages/matplotlib/axis.py:1798\u001b[0m, in \u001b[0;36mAxis._set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fontdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(fontdict)\n\u001b[0;32m-> 1798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_ticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.9/site-packages/matplotlib/axis.py:1720\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of ticklabels is often used as a way to\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 ticklabels\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ticklabels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1721\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1722\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1724\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of ticklabels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ticklabels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1725\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, ticklabels)}\n\u001b[1;32m   1726\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of ticklabels (3)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot train\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.2\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(svm_acc[0]))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, svm_acc[0], color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='SVM')\n",
    "plt.bar(br2, pop_acc[0], color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Population')\n",
    "plt.bar(br3, all_acc[0], color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='All accuracy')\n",
    "plt.bar(br4, prop_acc[0], color ='y', width = barWidth,\n",
    "        edgecolor ='grey', label ='Proportion')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Time constant (in ms)', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(1)],\n",
    "        endpoint_delays)\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "#plt.title(\"(a)\", fontsize=30)\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Accuracy values on training dataset for recurrents.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eafee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot test\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.2\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(svm_acc[1]))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, svm_acc[1], color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='SVM')\n",
    "plt.bar(br2, pop_acc[1], color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Population')\n",
    "plt.bar(br3, all_acc[1], color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='All accuracy')\n",
    "plt.bar(br4, prop_acc[1], color ='y', width = barWidth,\n",
    "        edgecolor ='grey', label ='Proportion')\n",
    " \n",
    "# Adding Xticks\n",
    "plt.xlabel('Time constant (in ms)', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(1)],\n",
    "        endpoint_delays)\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "#plt.title(\"(a)\", fontsize=30)\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Accuracy values on test dataset for recurrents.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
